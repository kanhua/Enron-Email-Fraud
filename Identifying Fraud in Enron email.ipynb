{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Fraud from Enron Email\n",
    "The aim of this project to identify person of interest (poi) in Enron scandal from a given dataset.\n",
    "Original dataset and starter's code can be downloaded from [this github repository](https://github.com/udacity/ud120-projects.git).\n",
    "\n",
    "The analysis is performed with the following procedure. We start with an exploratory analysis and then we clean the dataset based on some observations. After that, we add some new features into the dataset. Finally, we select features and run a couple of machine learning algrithms to identify ```poi```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "[Exploratory Analysis](#Exploratory-Analysis)\n",
    "\n",
    "[Removing outliers](#Removing-outliers)\n",
    "\n",
    "[Selecting features manually](#Selecting-features-manually)\n",
    "\n",
    "[Engineering new features](#Engineering-new-features)\n",
    "\n",
    "[Feature Selection](#Feature-selection)\n",
    "\n",
    "[Models of classification](#Models-of-classification)\n",
    "\n",
    "[More details on the validation of the models](#More-details-on-the-validation-of-the-models)\n",
    "\n",
    "[Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this implementation\n",
    "This implementation takes a slightly different approach compared with the starter's code. We first convert the raw data file ```final_project_dataset.pkl``` into a pandas dataframe object. Most of the exploratory analysis and operations of this dataset were performed using pandas library. This ipython notebook was tested using python 3.4.\n",
    "\n",
    "```final_project_dataset.pkl```: the original dataset. \n",
    "\n",
    "```scoring.py```: this file contains the function for evaluating the classification results.\n",
    "- ```calc_score()```: this function uses the same method as ```test_classifier``` in the starter's code to evalulate precision, recall and f1 scores.\n",
    "\n",
    "```preprocess_data.py```: this file contains the functions that do the preprocessing of the raw data.\n",
    "- ```pkl_to_df()```: Read the raw pkl file and convert the contents in the pkl file into a python dataframe.\n",
    "- ```extract_df()```: Return the features and labels in the dataframe as numpy arrays.\n",
    "- ```FeatureSel```: A class that selects the features using ```SelectKBest``` and ```PCA``` in ```sklearn```.\n",
    "- ```add_feature()```: This function takes logarithms of the financial features.\n",
    "\n",
    "```poi_id.py```: the mail file that does the classification. This is the final submission file for the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import scale,StandardScaler,Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from scoring import calc_score\n",
    "from preprocess_data import pkl_to_df,extract_df,linearsvc_outlier_rm,FeatureSel,add_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis\n",
    "In this section, we loads the data and explore some basic information of this dataset. Since the values in the feature *\"email_address\"* are string, we will exclude this feature throughout our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset and convert it to a pandas dataframe\n",
    "df=pkl_to_df(rows_to_remove=[],cols_to_remove=[\"email_address\"])\n",
    "df=df.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimension of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bonus', 'deferral_payments', 'deferred_income', 'director_fees',\n",
       "       'exercised_stock_options', 'expenses', 'from_messages',\n",
       "       'from_poi_to_this_person', 'from_this_person_to_poi', 'loan_advances',\n",
       "       'long_term_incentive', 'other', 'poi', 'restricted_stock',\n",
       "       'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi',\n",
       "       'to_messages', 'total_payments', 'total_stock_value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set has 145 entries and 21 features, including ```poi```. Note that we have already excluded \"email_address\" in the dataframe ```df```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics of dependent variable ```poi```\n",
    "We now use ```describe()``` function to explore the summary of the feature ```poi```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          146\n",
       "mean     0.1232877\n",
       "std      0.3298989\n",
       "min          False\n",
       "25%              0\n",
       "50%              0\n",
       "75%              0\n",
       "max           True\n",
       "Name: poi, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"poi\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean value indicates that only 12.4% of ```poi``` is ```True```. In the above result, ```count``` is the number of total non-NaN values. The ```count``` of ```poi``` equals to the total rows, showing that every row has a ```poi``` value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NaN in each feature\n",
    "We can then use ```transpose()``` and ```count``` to explore the ratio of non-NaN values in each feature: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                         0.5616438\n",
       "deferral_payments             0.2671233\n",
       "deferred_income               0.3356164\n",
       "director_fees                 0.1164384\n",
       "exercised_stock_options       0.6986301\n",
       "expenses                      0.6506849\n",
       "from_messages                 0.5890411\n",
       "from_poi_to_this_person       0.5890411\n",
       "from_this_person_to_poi       0.5890411\n",
       "loan_advances                0.02739726\n",
       "long_term_incentive           0.4520548\n",
       "other                         0.6369863\n",
       "poi                                   1\n",
       "restricted_stock              0.7534247\n",
       "restricted_stock_deferred     0.1232877\n",
       "salary                        0.6506849\n",
       "shared_receipt_with_poi       0.5890411\n",
       "to_messages                   0.5890411\n",
       "total_payments                0.8561644\n",
       "total_stock_value             0.8630137\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()[\"count\"]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that every feature has NaN values except ```poi```. The feature ```loan_advances``` has the lowest ratio of non-NaN data, which is only 2%. In the following analysis, we will treat these NaN as zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using random forests to classify the raw dataset\n",
    "We now set up a random forests classifier to test the results of the classificaion at each stage of data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.2852983988355167\n",
      "recall: 0.098\n",
      "f1: 0.14588760699665054\n"
     ]
    }
   ],
   "source": [
    "rf_dict=[] # a list of dictionary that stores the results\n",
    "rf=RandomForestClassifier()\n",
    "df.fillna(0,inplace=True)\n",
    "X,y,_=extract_df(df)\n",
    "score=calc_score(X,y,rf)\n",
    "score_dict={\"data\":\"raw\",\"dataframe\":\"df\"}\n",
    "score_dict.update(score)\n",
    "rf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will remove the data points that may not be appropriate to include for further analysis.\n",
    "As discussed in the mini-project of the course, the dataset includes an entry that is the total of the financial features. Therefore we should remove this entry *TOTAL* before further analyzing the data. Also, we found that all the features of *LOCKHART EUGENE E* are NaN except ```poi```. Thus it makes sense to remove this data entry as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bonus                            0\n",
       "deferral_payments                0\n",
       "deferred_income                  0\n",
       "director_fees                    0\n",
       "exercised_stock_options          0\n",
       "expenses                         0\n",
       "from_messages                    0\n",
       "from_poi_to_this_person          0\n",
       "from_this_person_to_poi          0\n",
       "loan_advances                    0\n",
       "long_term_incentive              0\n",
       "other                            0\n",
       "poi                          False\n",
       "restricted_stock                 0\n",
       "restricted_stock_deferred        0\n",
       "salary                           0\n",
       "shared_receipt_with_poi          0\n",
       "to_messages                      0\n",
       "total_payments                   0\n",
       "total_stock_value                0\n",
       "Name: LOCKHART EUGENE E, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\"LOCKHART EUGENE E\",:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will remove both *TOTAL*,*LOCKHART EUGENE E* and see how it affect the results of random forests classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.3701492537313433\n",
      "recall: 0.124\n",
      "f1: 0.18576779026217227\n"
     ]
    }
   ],
   "source": [
    "rows_to_remove=[\"TOTAL\",\"LOCKHART EUGENE E\"]\n",
    "ro_df=pkl_to_df(rows_to_remove=rows_to_remove)\n",
    "ro_df=ro_df.convert_objects(convert_numeric=True)\n",
    "X,y,_=extract_df(ro_df.fillna(0))\n",
    "score=calc_score(X,y,rf)\n",
    "score_dict={\"data\":\"removing outlier manually\",\"dataframe\":\"ro_df\"}\n",
    "score_dict.update(score)\n",
    "rf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that all the scores slightly improved after the outliters are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features manually\n",
    "First we use ```describe()``` to list the basic statistical information of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bonus</th>\n",
       "      <td>81</td>\n",
       "      <td>1201773</td>\n",
       "      <td>1441679</td>\n",
       "      <td>70000</td>\n",
       "      <td>425000</td>\n",
       "      <td>750000</td>\n",
       "      <td>1200000</td>\n",
       "      <td>8000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferral_payments</th>\n",
       "      <td>38</td>\n",
       "      <td>841602.5</td>\n",
       "      <td>1289323</td>\n",
       "      <td>-102500</td>\n",
       "      <td>79644.5</td>\n",
       "      <td>221063.5</td>\n",
       "      <td>867211.2</td>\n",
       "      <td>6426990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deferred_income</th>\n",
       "      <td>48</td>\n",
       "      <td>-581049.8</td>\n",
       "      <td>942076.4</td>\n",
       "      <td>-3504386</td>\n",
       "      <td>-611209.2</td>\n",
       "      <td>-151927</td>\n",
       "      <td>-37926</td>\n",
       "      <td>-833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>director_fees</th>\n",
       "      <td>16</td>\n",
       "      <td>89822.88</td>\n",
       "      <td>41112.7</td>\n",
       "      <td>3285</td>\n",
       "      <td>83674.5</td>\n",
       "      <td>106164.5</td>\n",
       "      <td>112815</td>\n",
       "      <td>137864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercised_stock_options</th>\n",
       "      <td>101</td>\n",
       "      <td>2959559</td>\n",
       "      <td>5499450</td>\n",
       "      <td>3285</td>\n",
       "      <td>506765</td>\n",
       "      <td>1297049</td>\n",
       "      <td>2542813</td>\n",
       "      <td>3.434838e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expenses</th>\n",
       "      <td>94</td>\n",
       "      <td>54192.01</td>\n",
       "      <td>46108.38</td>\n",
       "      <td>148</td>\n",
       "      <td>22479</td>\n",
       "      <td>46547.5</td>\n",
       "      <td>78408.5</td>\n",
       "      <td>228763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_messages</th>\n",
       "      <td>86</td>\n",
       "      <td>608.7907</td>\n",
       "      <td>1841.034</td>\n",
       "      <td>12</td>\n",
       "      <td>22.75</td>\n",
       "      <td>41</td>\n",
       "      <td>145.5</td>\n",
       "      <td>14368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_poi_to_this_person</th>\n",
       "      <td>86</td>\n",
       "      <td>64.89535</td>\n",
       "      <td>86.97924</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>72.25</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from_this_person_to_poi</th>\n",
       "      <td>86</td>\n",
       "      <td>41.23256</td>\n",
       "      <td>100.0731</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>24.75</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_advances</th>\n",
       "      <td>3</td>\n",
       "      <td>2.7975e+07</td>\n",
       "      <td>4.638256e+07</td>\n",
       "      <td>400000</td>\n",
       "      <td>1200000</td>\n",
       "      <td>2000000</td>\n",
       "      <td>4.17625e+07</td>\n",
       "      <td>8.1525e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_term_incentive</th>\n",
       "      <td>65</td>\n",
       "      <td>746491.2</td>\n",
       "      <td>862917.4</td>\n",
       "      <td>69223</td>\n",
       "      <td>275000</td>\n",
       "      <td>422158</td>\n",
       "      <td>831809</td>\n",
       "      <td>5145434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>92</td>\n",
       "      <td>465276.7</td>\n",
       "      <td>1389719</td>\n",
       "      <td>2</td>\n",
       "      <td>1209</td>\n",
       "      <td>51984.5</td>\n",
       "      <td>357577.2</td>\n",
       "      <td>1.035973e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poi</th>\n",
       "      <td>144</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.3318733</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock</th>\n",
       "      <td>109</td>\n",
       "      <td>1147424</td>\n",
       "      <td>2249770</td>\n",
       "      <td>-2604490</td>\n",
       "      <td>252055</td>\n",
       "      <td>441096</td>\n",
       "      <td>985032</td>\n",
       "      <td>1.476169e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restricted_stock_deferred</th>\n",
       "      <td>17</td>\n",
       "      <td>621892.8</td>\n",
       "      <td>3845528</td>\n",
       "      <td>-1787380</td>\n",
       "      <td>-329825</td>\n",
       "      <td>-140264</td>\n",
       "      <td>-72419</td>\n",
       "      <td>1.545629e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salary</th>\n",
       "      <td>94</td>\n",
       "      <td>284087.5</td>\n",
       "      <td>177131.1</td>\n",
       "      <td>477</td>\n",
       "      <td>211802</td>\n",
       "      <td>258741</td>\n",
       "      <td>308606.5</td>\n",
       "      <td>1111258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_receipt_with_poi</th>\n",
       "      <td>86</td>\n",
       "      <td>1176.465</td>\n",
       "      <td>1178.318</td>\n",
       "      <td>2</td>\n",
       "      <td>249.75</td>\n",
       "      <td>740.5</td>\n",
       "      <td>1888.25</td>\n",
       "      <td>5521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to_messages</th>\n",
       "      <td>86</td>\n",
       "      <td>2073.86</td>\n",
       "      <td>2582.701</td>\n",
       "      <td>57</td>\n",
       "      <td>541.25</td>\n",
       "      <td>1211</td>\n",
       "      <td>2634.75</td>\n",
       "      <td>15149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_payments</th>\n",
       "      <td>124</td>\n",
       "      <td>2623421</td>\n",
       "      <td>9488106</td>\n",
       "      <td>148</td>\n",
       "      <td>386380.2</td>\n",
       "      <td>1100246</td>\n",
       "      <td>2084663</td>\n",
       "      <td>1.035598e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_stock_value</th>\n",
       "      <td>125</td>\n",
       "      <td>3352073</td>\n",
       "      <td>6532883</td>\n",
       "      <td>-44093</td>\n",
       "      <td>494136</td>\n",
       "      <td>1095040</td>\n",
       "      <td>2606763</td>\n",
       "      <td>4.911008e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count        mean           std      min       25%  \\\n",
       "bonus                        81     1201773       1441679    70000    425000   \n",
       "deferral_payments            38    841602.5       1289323  -102500   79644.5   \n",
       "deferred_income              48   -581049.8      942076.4 -3504386 -611209.2   \n",
       "director_fees                16    89822.88       41112.7     3285   83674.5   \n",
       "exercised_stock_options     101     2959559       5499450     3285    506765   \n",
       "expenses                     94    54192.01      46108.38      148     22479   \n",
       "from_messages                86    608.7907      1841.034       12     22.75   \n",
       "from_poi_to_this_person      86    64.89535      86.97924        0        10   \n",
       "from_this_person_to_poi      86    41.23256      100.0731        0         1   \n",
       "loan_advances                 3  2.7975e+07  4.638256e+07   400000   1200000   \n",
       "long_term_incentive          65    746491.2      862917.4    69223    275000   \n",
       "other                        92    465276.7       1389719        2      1209   \n",
       "poi                         144       0.125     0.3318733    False         0   \n",
       "restricted_stock            109     1147424       2249770 -2604490    252055   \n",
       "restricted_stock_deferred    17    621892.8       3845528 -1787380   -329825   \n",
       "salary                       94    284087.5      177131.1      477    211802   \n",
       "shared_receipt_with_poi      86    1176.465      1178.318        2    249.75   \n",
       "to_messages                  86     2073.86      2582.701       57    541.25   \n",
       "total_payments              124     2623421       9488106      148  386380.2   \n",
       "total_stock_value           125     3352073       6532883   -44093    494136   \n",
       "\n",
       "                                50%          75%           max  \n",
       "bonus                        750000      1200000       8000000  \n",
       "deferral_payments          221063.5     867211.2       6426990  \n",
       "deferred_income             -151927       -37926          -833  \n",
       "director_fees              106164.5       112815        137864  \n",
       "exercised_stock_options     1297049      2542813  3.434838e+07  \n",
       "expenses                    46547.5      78408.5        228763  \n",
       "from_messages                    41        145.5         14368  \n",
       "from_poi_to_this_person          35        72.25           528  \n",
       "from_this_person_to_poi           8        24.75           609  \n",
       "loan_advances               2000000  4.17625e+07    8.1525e+07  \n",
       "long_term_incentive          422158       831809       5145434  \n",
       "other                       51984.5     357577.2  1.035973e+07  \n",
       "poi                               0            0          True  \n",
       "restricted_stock             441096       985032  1.476169e+07  \n",
       "restricted_stock_deferred   -140264       -72419  1.545629e+07  \n",
       "salary                       258741     308606.5       1111258  \n",
       "shared_receipt_with_poi       740.5      1888.25          5521  \n",
       "to_messages                    1211      2634.75         15149  \n",
       "total_payments              1100246      2084663  1.035598e+08  \n",
       "total_stock_value           1095040      2606763  4.911008e+07  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ro_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above result, we noticed that only three entries of the feature *loan_advances* has values, it is reasonable to ignore this feature to reduce the variances in the model. The following test shows that leaving out this feature for classification increase the overall precision, recall and f1 scores a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.363914373088685\n",
      "recall: 0.119\n",
      "f1: 0.17935192162773173\n"
     ]
    }
   ],
   "source": [
    "sf1_df=ro_df.drop([\"loan_advances\"],axis=1)\n",
    "sf1_df=sf1_df.convert_objects(convert_numeric=True)\n",
    "sf1_df=ro_df.copy()\n",
    "X,y,_=extract_df(sf1_df.fillna(0))\n",
    "score=calc_score(X,y,rf)\n",
    "score_dict={\"data\":\"removing loan_advances\",\"dataframe\":\"sf1_df\"}\n",
    "score_dict.update(score)\n",
    "rf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that many financial features in this dataset has very wide range. The difference can be several orders of magnitudes. This distribution can potentially biased the results of classifications. Take the feature ```exercised_stock_options``` for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10eba79b0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAENCAYAAAD9koUjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ec9b2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f=\"exercised_stock_options\"\n",
    "sf1_df[f].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we can see a long tail at large values of ```exercised_stock_options```. Taking logarithms of the feature ```exercised_stock_options``` makes the distribution less skewed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11032b470>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEACAYAAAB4ayemAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110326898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.log10(sf1_df[f]).hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, we can keep the data with extreme values but reduces its impact on classification. Since we can only perform logarithms on postive numbers, we thus adopt the following tricks to deal with zeros and negative numbers.\n",
    "1. Filling NaN or zeros values in raw data with zeros in the logarithmic features. We can do this because the financial features can never be less than 1 ($10^0$). Also, 0 and 1 have no substantial differences in these financial features.\n",
    "2. If a financial feature has negative values, we convert it into two features. One stores the positive values, and another store the negative values. For example, ```p_total_stock_value``` stores postivie values of ```total_stock_value```, while ```n_total_stock_value``` stores negative values of ```total_stock_value```.\n",
    "\n",
    "These operations are implemented in ```add_features()``` in ```preprocess_data.py```. Since we make this function compatible with the data structure used in ```poi_id.py```, we have to reload the raw data file, perform ```add_features()```, and converti it to pandas dataframe again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pkl_file=\"./data/final_project_dataset.pkl\"\n",
    "data_dict=pickle.load(open(pkl_file,\"rb\"),fix_imports=False,encoding=\"latin1\")\n",
    "\n",
    "# Features to be included. Everything except \"email_address\" and \"loan_advances\"\n",
    "features_list = ['poi', 'bonus', 'deferral_payments', 'deferred_income', 'director_fees',\n",
    "                 'exercised_stock_options', 'expenses', 'from_messages',\n",
    "                 'from_poi_to_this_person', 'from_this_person_to_poi',\n",
    "                 'long_term_incentive', 'other', 'restricted_stock',\n",
    "                 'restricted_stock_deferred', 'salary', 'shared_receipt_with_poi',\n",
    "                 'to_messages', 'total_payments', 'total_stock_value']\n",
    "\n",
    "# Delete the outliers\n",
    "del data_dict[\"TOTAL\"]\n",
    "del data_dict[\"LOCKHART EUGENE E\"]\n",
    "\n",
    "# Take logarithms of finanacial features\n",
    "my_dataset, new_feature_names, financial_features = add_features(data_dict)\n",
    "\n",
    "# Convert the data to pandas dataframe\n",
    "sf2_df=pd.DataFrame(data_dict)\n",
    "sf2_df=sf2_df.convert_objects(convert_numeric=True)\n",
    "sf2_df=sf2_df.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we test this processed dataset using random forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.3885630498533724\n",
      "recall: 0.1325\n",
      "f1: 0.197613721103654\n"
     ]
    }
   ],
   "source": [
    "X,y,_=extract_df(sf2_df.fillna(0))\n",
    "score=calc_score(X,y,rf)\n",
    "score_dict={\"data\":\"adding new features\",\"dataframe\":\"sf2_df\"}\n",
    "score_dict.update(score)\n",
    "rf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the scores are slightly improved by using the new preprocessed dataset.\n",
    "## Summary of results of random forests\n",
    "Here we summarize the the results of each stage of data preporocessing using random forests classifier in the following table. The variation of *precision*, *recall* and *f1* are +/- 0.01. These scores are caculated by summing TP, TF, FP, FN 1000 times using stratified cross validation. This procedure is identical to the scoring function provided by the startup code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>dataframe</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raw</td>\n",
       "      <td>df</td>\n",
       "      <td>0.145888</td>\n",
       "      <td>0.285298</td>\n",
       "      <td>0.0980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>removing outlier manually</td>\n",
       "      <td>ro_df</td>\n",
       "      <td>0.185768</td>\n",
       "      <td>0.370149</td>\n",
       "      <td>0.1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>removing loan_advances</td>\n",
       "      <td>sf1_df</td>\n",
       "      <td>0.179352</td>\n",
       "      <td>0.363914</td>\n",
       "      <td>0.1190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adding new features</td>\n",
       "      <td>sf2_df</td>\n",
       "      <td>0.197614</td>\n",
       "      <td>0.388563</td>\n",
       "      <td>0.1325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        data dataframe        f1  precision  recall\n",
       "0                        raw        df  0.145888   0.285298  0.0980\n",
       "1  removing outlier manually     ro_df  0.185768   0.370149  0.1240\n",
       "2     removing loan_advances    sf1_df  0.179352   0.363914  0.1190\n",
       "3        adding new features    sf2_df  0.197614   0.388563  0.1325"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_score_df=pd.DataFrame(rf_dict)\n",
    "rf_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "We combine two approaches to select features for training, one is univariate feature selection, and the other is principle component analysis. We select *m* features using ```SelectKBest``` is sklearn and select another *n* features using ```pca```, and then use these *m+n* features for classification. The values of *m* and *n* will be chosen by cross-validation. We wrap these process into the class ```FeatureSel```, which is compatible with standards defined by *sklearn* so that we can incorporate it into a sklearn ```Pipeline```. The implementation of this class is in [preprocess_data.py](./preprocess_data.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models of classification\n",
    "\n",
    "### Procedures of running the classification\n",
    "We will run three classification models: linear support vector machine(```LinearSVC```) and AdaBoost (```AdaBoostClassifier```). We use ```Pipeline``` class in sklearn to combine these algorithms with our ```FeatureSel``` class. A ```Pipeline``` has the following three components:\n",
    "\n",
    "1. ```FeatureSel```: As mentioned in the previous section, this class select and combines the features yielded by ```SelectKBest``` and ```pca```.\n",
    "2. ```StandardScaler```: Rescle the data if it is necessary for the classifier.\n",
    "3. ```ChoiceOfClassifier```: The main algorithm for calssification.\n",
    "\n",
    "### Tuning the model with cross validation\n",
    "We also set up a ```GridSearchCV``` class that scans some key parameter to fine tune the model. From those preliminary tests using random forests, we find that the values of *precision* can easily meet the specification but the values of *recall* are low. Thus we will set our ```GridSearchCV``` objects to optimize *recall*.\n",
    "### LinearSVC\n",
    "First we use linear support vector machine (```LinearSVC```) to do the classification on both the dataset that with and without feature engineering. The parameters that we choose to optimize are C value of ```LinearSVC``` and the number of components selected by ```SelectKBest``` and ```pca```. C value is a regularization parameter. Larger C gives lower bias but higher variance, whereas smaller C gives higher bias but lower variance on the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC with the data without feature engineering, with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('fsl', FeatureSel(k_best=1, pca_comp=0)), ('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lvc', LinearSVC(C=9.9999999999999995e-07, class_weight=None, dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='l2', multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])\n",
      "precision: 0.37244897959183676\n",
      "recall: 0.3285\n",
      "f1: 0.34909670563230605\n"
     ]
    }
   ],
   "source": [
    "clf_dict=[] # A list that stores the test conditions and scores\n",
    "fill_test_df=sf1_df.fillna(0)\n",
    "nX,y,cols=extract_df(fill_test_df)\n",
    "fsl=FeatureSel(k_best=5,pca_comp=5)\n",
    "sd=StandardScaler()\n",
    "ppl=Pipeline([(\"fsl\",fsl),(\"sd\",sd),(\"lvc\",LinearSVC())])\n",
    "gscv=GridSearchCV(ppl,{\"lvc__C\":np.logspace(-6,-1,5),\n",
    "                  \"fsl__k_best\":[1,5,10],\"fsl__pca_comp\":[0,5,10]},\n",
    "                  scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX,y)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX,y,gscv.best_estimator_,n_iter=100)\n",
    "score_dict={\"dataframe\":\"sf1_df\",\n",
    "            \"feature engineering\":False,\n",
    "           \"feature selection\":True,\n",
    "           \"algorithm\":\"LinearSVC\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC with the data without feature engineering, without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lvc', LinearSVC(C=9.9999999999999995e-07, class_weight=None, dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='l2', multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])\n",
      "precision: 0.2608843537414966\n",
      "recall: 0.3835\n",
      "f1: 0.3105263157894737\n"
     ]
    }
   ],
   "source": [
    "fill_test_df=sf1_df.fillna(0)\n",
    "nX,y,cols=extract_df(fill_test_df)\n",
    "sd=StandardScaler()\n",
    "ppl_nofsl=Pipeline([(\"sd\",sd),(\"lvc\",LinearSVC())])\n",
    "gscv=GridSearchCV(ppl_nofsl,{\"lvc__C\":np.logspace(-6,-1,10)},scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX,y)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX,y,gscv.best_estimator_,n_iter=100)\n",
    "score_dict={\"dataframe\":\"sf1_df\",\n",
    "            \"feature engineering\":False,\n",
    "           \"feature selection\":False,\n",
    "           \"algorithm\":\"LinearSVC\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC with the dataset with feature engineering, with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('fsl', FeatureSel(k_best=1, pca_comp=0)), ('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lvc', LinearSVC(C=9.9999999999999995e-07, class_weight=None, dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='l2', multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])\n",
      "precision: 0.3839378238341969\n",
      "recall: 0.3705\n",
      "f1: 0.37709923664122136\n"
     ]
    }
   ],
   "source": [
    "fill_test_df=sf2_df.fillna(0)\n",
    "nX2,ny,cols=extract_df(fill_test_df)\n",
    "fsl=FeatureSel(k_best=5,pca_comp=5)\n",
    "sd=StandardScaler()\n",
    "ppl=Pipeline([(\"fsl\",fsl),(\"sd\",sd),(\"lvc\",LinearSVC())])\n",
    "gscv=GridSearchCV(ppl,{\"lvc__C\":np.logspace(-6,-1,5),\n",
    "                       \"fsl__k_best\":[1,5,10],\n",
    "                       \"fsl__pca_comp\":[0,5,10]},\n",
    "                  scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX2,ny)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX2,ny,gscv.best_estimator_,n_iter=100)\n",
    "score_dict={\"dataframe\":\"sf2_df\",\n",
    "            \"feature engineering\":True,\n",
    "           \"feature selection\":True,\n",
    "           \"algorithm\":\"LinearSVC\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC with the dataset with feature engineering, without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lvc', LinearSVC(C=9.9999999999999995e-07, class_weight=None, dual=True,\n",
      "     fit_intercept=True, intercept_scaling=1, loss='l2', multi_class='ovr',\n",
      "     penalty='l2', random_state=None, tol=0.0001, verbose=0))])\n",
      "precision: 0.2916147409649279\n",
      "recall: 0.819\n",
      "f1: 0.4300905868452147\n"
     ]
    }
   ],
   "source": [
    "fill_test_df=sf2_df.fillna(0)\n",
    "nX,y,cols=extract_df(fill_test_df)\n",
    "sd=StandardScaler()\n",
    "ppl_nofsl=Pipeline([(\"sd\",sd),(\"lvc\",LinearSVC())])\n",
    "gscv=GridSearchCV(ppl_nofsl,{\"lvc__C\":np.logspace(-6,-1,5)},scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX,y)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX,y,gscv,n_iter=100)\n",
    "score_dict={\"dataframe\":\"sf2_df\",\n",
    "            \"feature engineering\":True,\n",
    "           \"feature selection\":False,\n",
    "           \"algorithm\":\"LinearSVC\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost classification\n",
    "We will also try AdaBoost and see if it can outperforms the reusults given by LinearSVC. The pipeline we set up is almost the same as the one we used in previous section, except that we repalce ```LinearSVC``` by ```AdaBoostClassifier```.\n",
    "\n",
    "The parameter that we will tune is the learning rate. This parameter controls how much the model is adjusted after each iteration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the dataset with feature engineering, with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('fsl', FeatureSel(k_best=1, pca_comp=0)), ('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=9.9999999999999995e-07, n_estimators=50,\n",
      "          random_state=None))])\n",
      "precision: 0.21359223300970873\n",
      "recall: 0.066\n",
      "f1: 0.10084033613445378\n"
     ]
    }
   ],
   "source": [
    "fill_test_df=sf2_df.fillna(0)\n",
    "nX,y,cols=extract_df(fill_test_df)\n",
    "fsl=FeatureSel(k_best=5,pca_comp=5)\n",
    "sd=StandardScaler()\n",
    "ppl=Pipeline([(\"fsl\",fsl),('sd',sd),(\"rf\",AdaBoostClassifier())])\n",
    "gscv=GridSearchCV(ppl,{\"rf__learning_rate\":np.logspace(-6,0,5),\n",
    "                       \"fsl__k_best\":[1,5,10],\"fsl__pca_comp\":[0,5,10]},\n",
    "                  scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX,y)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX,y,gscv.best_estimator_)\n",
    "score_dict={\"dataframe\":\"sf2_df\",\n",
    "            \"feature engineering\":True,\n",
    "           \"feature selection\":True,\n",
    "           \"algorithm\":\"AdaBoost\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the dataset with feature engineering, without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.031622776601683791, n_estimators=50,\n",
      "          random_state=None))])\n",
      "precision: 0.5714285714285714\n",
      "recall: 0.106\n",
      "f1: 0.17882749894559258\n"
     ]
    }
   ],
   "source": [
    "fill_test_df=sf2_df.fillna(0)\n",
    "nX,y,cols=extract_df(fill_test_df)\n",
    "fsl=FeatureSel(k_best=5,pca_comp=5)\n",
    "sd=StandardScaler()\n",
    "ppl=Pipeline([('sd',sd),(\"rf\",AdaBoostClassifier())])\n",
    "gscv=GridSearchCV(ppl,{\"rf__learning_rate\":np.logspace(-6,0,5)},scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX,y)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX,y,gscv.best_estimator_)\n",
    "score_dict={\"dataframe\":\"sf2_df\",\n",
    "            \"feature engineering\":True,\n",
    "           \"feature selection\":False,\n",
    "           \"algorithm\":\"AdaBoost\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset without feature engineering, without feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "precision: 0.39927007299270073\n",
      "recall: 0.2735\n",
      "f1: 0.32462908011869435\n"
     ]
    }
   ],
   "source": [
    "fill_test_df=sf1_df.fillna(0)\n",
    "nX,y,cols=extract_df(fill_test_df)\n",
    "fsl=FeatureSel(k_best=5,pca_comp=5)\n",
    "sd=StandardScaler()\n",
    "ppl=Pipeline([(\"sd\",sd),(\"rf\",AdaBoostClassifier())])\n",
    "gscv=GridSearchCV(ppl,{\"rf__learning_rate\":np.logspace(-6,0,5)},scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX,y)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX,y,gscv.best_estimator_)\n",
    "score_dict={\"dataframe\":\"sf1_df\",\n",
    "            \"feature engineering\":False,\n",
    "           \"feature selection\":False,\n",
    "           \"algorithm\":\"AdaBoost\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset without feature engineering, with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('fsl', FeatureSel(k_best=1, pca_comp=0)), ('sd', StandardScaler(copy=True, with_mean=True, with_std=True)), ('rf', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None))])\n",
      "precision: 0.30787781350482313\n",
      "recall: 0.1915\n",
      "f1: 0.23612823674475955\n"
     ]
    }
   ],
   "source": [
    "fill_test_df=sf1_df.fillna(0)\n",
    "nX,y,cols=extract_df(fill_test_df)\n",
    "fsl=FeatureSel(k_best=5,pca_comp=5)\n",
    "sd=StandardScaler()\n",
    "ppl=Pipeline([(\"fsl\",fsl),(\"sd\",sd),(\"rf\",AdaBoostClassifier())])\n",
    "gscv=GridSearchCV(ppl,{\"rf__learning_rate\":np.logspace(-6,0,5),\n",
    "                       \"fsl__k_best\":[1,5,10],\"fsl__pca_comp\":[0,5,10]},\n",
    "                  scoring=\"recall\",verbose=0)\n",
    "gscv.fit(nX,y)\n",
    "print(gscv.best_estimator_)\n",
    "score=calc_score(nX,y,gscv.best_estimator_)\n",
    "score_dict={\"dataframe\":\"sf1_df\",\n",
    "            \"feature engineering\":False,\n",
    "           \"feature selection\":True,\n",
    "           \"algorithm\":\"AdaBoost\"}\n",
    "score_dict.update(score)\n",
    "clf_dict.append(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores of the classification algorithms\n",
    "The scores of the above algorithms are listed in the following table. Due to the randomness of cross-validation, the variation of each scores listed in the table are around +/- 0.02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>dataframe</th>\n",
       "      <th>f1</th>\n",
       "      <th>feature engineering</th>\n",
       "      <th>feature selection</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>sf1_df</td>\n",
       "      <td>0.349097</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.372449</td>\n",
       "      <td>0.3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>sf1_df</td>\n",
       "      <td>0.310526</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.260884</td>\n",
       "      <td>0.3835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>sf2_df</td>\n",
       "      <td>0.377099</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.383938</td>\n",
       "      <td>0.3705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>sf2_df</td>\n",
       "      <td>0.430091</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.291615</td>\n",
       "      <td>0.8190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>sf2_df</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.213592</td>\n",
       "      <td>0.0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>sf2_df</td>\n",
       "      <td>0.178827</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>sf1_df</td>\n",
       "      <td>0.324629</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.399270</td>\n",
       "      <td>0.2735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>sf1_df</td>\n",
       "      <td>0.236128</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.307878</td>\n",
       "      <td>0.1915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm dataframe        f1 feature engineering feature selection  \\\n",
       "0  LinearSVC    sf1_df  0.349097               False              True   \n",
       "1  LinearSVC    sf1_df  0.310526               False             False   \n",
       "2  LinearSVC    sf2_df  0.377099                True              True   \n",
       "3  LinearSVC    sf2_df  0.430091                True             False   \n",
       "4   AdaBoost    sf2_df  0.100840                True              True   \n",
       "5   AdaBoost    sf2_df  0.178827                True             False   \n",
       "6   AdaBoost    sf1_df  0.324629               False             False   \n",
       "7   AdaBoost    sf1_df  0.236128               False              True   \n",
       "\n",
       "   precision  recall  \n",
       "0   0.372449  0.3285  \n",
       "1   0.260884  0.3835  \n",
       "2   0.383938  0.3705  \n",
       "3   0.291615  0.8190  \n",
       "4   0.213592  0.0660  \n",
       "5   0.571429  0.1060  \n",
       "6   0.399270  0.2735  \n",
       "7   0.307878  0.1915  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_df=pd.DataFrame(clf_dict)\n",
    "clf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More details on the validation of the models\n",
    "We implement ```calc_score()``` to evaluate the performance of our algorithms. ```calc_score()``` runs stratified cross validation for 1000 times. For each run, it takes 10% of the data as the test dataset and the remaining 90% of the data as the training dataset. After the model is fitted using the training set, it tests the model with the test set and calculate the number of true posivies (TP), false positives (FP), false negatives (FN) and true negatives (TN). After these iterations finish, it sums up the TP, FP, FN and TN of all iterations, and then calculate recall, precision and f1 score.\n",
    "\n",
    "We adopt this method instead of averaging each metric such as recall or precision because this dataset is small and the portions of the ```poi=True``` is only 10%. Therefore, variations of the scoring metrics between each run would be very large.\n",
    "\n",
    "The three metrics we used are defined as below: \n",
    "\n",
    "- *precision* measures the ratio of TP among all the population that are predicted as ```poi```, namely,\n",
    "\n",
    "\\begin{align}\n",
    "precision=\\frac{TP}{TP+FP}\n",
    "\\end{align}\n",
    "\n",
    "- *recall* measures the ratio of TP among all the population that are ```poi```, namely,\n",
    "\n",
    "\\begin{align}\n",
    "recall=\\frac{TP}{TP+FN}\n",
    "\\end{align}\n",
    "\n",
    "*Precision* and *recall* are chosen to be the metrics instead of *accuracy* because the population of ```poi=True``` are small, and *accuracy* cannot reflect the real predictive power of our model.\n",
    "\n",
    "\n",
    "- *f1 score* is the harmonic mean of *precision* and *recall*:\n",
    "\\begin{align}\n",
    "f1= \\frac{2 \\cdot precision \\cdot recall}{precision+recall}\n",
    "\\end{align}\n",
    "\n",
    "This metric can be considered as a kind of average of *precision* and *recall*.\n",
    "\n",
    "By using these metrics to evaluate our model, the most performant model are linearSVC, with or without feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "In this report, we demonstrated a model to predict ```poi``` in the Enron dataset that could achieve f1 scores larger than 0.3. We first remove a couple of data entries that are not appropriate for further analysis, and exclude a feature that are mostly NaNs. After that, we use both univariate method and principle component analysis as the way to select features. Finally, we use AdaBoost and linear support vector machine to predict ```poi```. Cross-validation shows that linear support vector machine is more accurate in predicting ```poi```, giving f1 scores over 0.3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
